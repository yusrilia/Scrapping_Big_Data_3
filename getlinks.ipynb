{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlinksold(page):\n",
    "    # Setup Selenium WebDriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run in headless mode (optional)\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    # Open the page\n",
    "    url = \"http://www.iqplus.info/news/stock_news/go-to-page,\"+str(page)+\".html\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # Find the \"STOCK NEWS MORE\" section\n",
    "    stock_news_section = driver.find_element(By.XPATH, \"//h2[contains(text(),'STOCK NEWS MORE')]/following-sibling::ul\")\n",
    "\n",
    "    # Extract article links within the section\n",
    "    article_links = set()\n",
    "    articles = stock_news_section.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "    for article in articles:\n",
    "        link = article.get_attribute(\"href\")\n",
    "        if link:\n",
    "            article_links.add(link)\n",
    "\n",
    "    # Append links to a text file\n",
    "    with open(\"stock_news_links.txt\", \"a\", encoding=\"utf-8\") as file:\n",
    "        for link in article_links:\n",
    "            file.write(link + \"\\n\")\n",
    "\n",
    "    # Close browser\n",
    "    driver.quit()\n",
    "\n",
    "    print(\"links from page\" page, \"have been added to stock_news_links.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlinks(page):\n",
    "\n",
    "    # Setup Selenium WebDriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run in headless mode\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    # Open the page\n",
    "    url = \"http://www.iqplus.info/news/stock_news/go-to-page,\"+str(page)+\".html\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the \"STOCK NEWS MORE\" section to load\n",
    "    try:\n",
    "        stock_news_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//h2[contains(text(),'STOCK NEWS MORE')]/following-sibling::ul\"))\n",
    "        )\n",
    "\n",
    "        # Extract article links\n",
    "        article_links = set()\n",
    "        articles = stock_news_section.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "        for article in articles:\n",
    "            link = article.get_attribute(\"href\")\n",
    "            if link:\n",
    "                article_links.add(link)\n",
    "\n",
    "        # Append links to a text file\n",
    "        with open(\"stock_news_links.txt\", \"a\", encoding=\"utf-8\") as file:\n",
    "            for link in article_links:\n",
    "                file.write(link + \"\\n\")\n",
    "\n",
    "        print(\"links from page\", page, \"have been added to stock_news_links.txt\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "links from page 141 have been added to stock_news_links.txt\n"
     ]
    }
   ],
   "source": [
    "getlinks(141)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "links from page 141 have been added to stock_news_links.txt\n",
      "links from page 140 have been added to stock_news_links.txt\n",
      "links from page 139 have been added to stock_news_links.txt\n",
      "links from page 138 have been added to stock_news_links.txt\n",
      "links from page 137 have been added to stock_news_links.txt\n",
      "links from page 136 have been added to stock_news_links.txt\n",
      "links from page 135 have been added to stock_news_links.txt\n",
      "links from page 134 have been added to stock_news_links.txt\n",
      "links from page 133 have been added to stock_news_links.txt\n",
      "links from page 132 have been added to stock_news_links.txt\n",
      "links from page 131 have been added to stock_news_links.txt\n",
      "links from page 130 have been added to stock_news_links.txt\n",
      "links from page 129 have been added to stock_news_links.txt\n",
      "links from page 128 have been added to stock_news_links.txt\n",
      "links from page 127 have been added to stock_news_links.txt\n",
      "links from page 126 have been added to stock_news_links.txt\n",
      "links from page 125 have been added to stock_news_links.txt\n",
      "links from page 124 have been added to stock_news_links.txt\n",
      "links from page 123 have been added to stock_news_links.txt\n",
      "links from page 122 have been added to stock_news_links.txt\n",
      "links from page 121 have been added to stock_news_links.txt\n",
      "links from page 120 have been added to stock_news_links.txt\n",
      "links from page 119 have been added to stock_news_links.txt\n",
      "links from page 118 have been added to stock_news_links.txt\n",
      "links from page 117 have been added to stock_news_links.txt\n",
      "links from page 116 have been added to stock_news_links.txt\n",
      "links from page 115 have been added to stock_news_links.txt\n",
      "links from page 114 have been added to stock_news_links.txt\n",
      "links from page 113 have been added to stock_news_links.txt\n",
      "links from page 112 have been added to stock_news_links.txt\n",
      "links from page 111 have been added to stock_news_links.txt\n",
      "links from page 110 have been added to stock_news_links.txt\n",
      "links from page 109 have been added to stock_news_links.txt\n",
      "links from page 108 have been added to stock_news_links.txt\n",
      "links from page 107 have been added to stock_news_links.txt\n",
      "links from page 106 have been added to stock_news_links.txt\n",
      "links from page 105 have been added to stock_news_links.txt\n",
      "links from page 104 have been added to stock_news_links.txt\n",
      "links from page 103 have been added to stock_news_links.txt\n",
      "links from page 102 have been added to stock_news_links.txt\n",
      "links from page 101 have been added to stock_news_links.txt\n",
      "links from page 100 have been added to stock_news_links.txt\n",
      "links from page 99 have been added to stock_news_links.txt\n",
      "links from page 98 have been added to stock_news_links.txt\n",
      "links from page 97 have been added to stock_news_links.txt\n",
      "links from page 96 have been added to stock_news_links.txt\n",
      "links from page 95 have been added to stock_news_links.txt\n",
      "links from page 94 have been added to stock_news_links.txt\n",
      "links from page 93 have been added to stock_news_links.txt\n",
      "links from page 92 have been added to stock_news_links.txt\n",
      "links from page 91 have been added to stock_news_links.txt\n",
      "links from page 90 have been added to stock_news_links.txt\n",
      "links from page 89 have been added to stock_news_links.txt\n",
      "links from page 88 have been added to stock_news_links.txt\n",
      "links from page 87 have been added to stock_news_links.txt\n",
      "links from page 86 have been added to stock_news_links.txt\n",
      "links from page 85 have been added to stock_news_links.txt\n",
      "links from page 84 have been added to stock_news_links.txt\n",
      "links from page 83 have been added to stock_news_links.txt\n",
      "links from page 82 have been added to stock_news_links.txt\n",
      "links from page 81 have been added to stock_news_links.txt\n",
      "links from page 80 have been added to stock_news_links.txt\n",
      "links from page 79 have been added to stock_news_links.txt\n",
      "links from page 78 have been added to stock_news_links.txt\n",
      "links from page 77 have been added to stock_news_links.txt\n",
      "links from page 76 have been added to stock_news_links.txt\n",
      "links from page 75 have been added to stock_news_links.txt\n",
      "links from page 74 have been added to stock_news_links.txt\n",
      "links from page 73 have been added to stock_news_links.txt\n",
      "links from page 72 have been added to stock_news_links.txt\n",
      "links from page 71 have been added to stock_news_links.txt\n",
      "links from page 70 have been added to stock_news_links.txt\n",
      "links from page 69 have been added to stock_news_links.txt\n",
      "links from page 68 have been added to stock_news_links.txt\n",
      "links from page 67 have been added to stock_news_links.txt\n",
      "links from page 66 have been added to stock_news_links.txt\n",
      "links from page 65 have been added to stock_news_links.txt\n",
      "links from page 64 have been added to stock_news_links.txt\n",
      "links from page 63 have been added to stock_news_links.txt\n",
      "links from page 62 have been added to stock_news_links.txt\n",
      "links from page 61 have been added to stock_news_links.txt\n",
      "links from page 60 have been added to stock_news_links.txt\n",
      "links from page 59 have been added to stock_news_links.txt\n",
      "links from page 58 have been added to stock_news_links.txt\n",
      "links from page 57 have been added to stock_news_links.txt\n",
      "links from page 56 have been added to stock_news_links.txt\n",
      "links from page 55 have been added to stock_news_links.txt\n",
      "links from page 54 have been added to stock_news_links.txt\n",
      "links from page 53 have been added to stock_news_links.txt\n",
      "links from page 52 have been added to stock_news_links.txt\n",
      "links from page 51 have been added to stock_news_links.txt\n",
      "links from page 50 have been added to stock_news_links.txt\n",
      "links from page 49 have been added to stock_news_links.txt\n",
      "links from page 48 have been added to stock_news_links.txt\n",
      "links from page 47 have been added to stock_news_links.txt\n",
      "links from page 46 have been added to stock_news_links.txt\n",
      "links from page 45 have been added to stock_news_links.txt\n",
      "links from page 44 have been added to stock_news_links.txt\n",
      "links from page 43 have been added to stock_news_links.txt\n",
      "links from page 42 have been added to stock_news_links.txt\n",
      "links from page 41 have been added to stock_news_links.txt\n",
      "links from page 40 have been added to stock_news_links.txt\n",
      "links from page 39 have been added to stock_news_links.txt\n",
      "links from page 38 have been added to stock_news_links.txt\n",
      "links from page 37 have been added to stock_news_links.txt\n",
      "links from page 36 have been added to stock_news_links.txt\n",
      "links from page 35 have been added to stock_news_links.txt\n",
      "links from page 34 have been added to stock_news_links.txt\n",
      "links from page 33 have been added to stock_news_links.txt\n",
      "links from page 32 have been added to stock_news_links.txt\n",
      "links from page 31 have been added to stock_news_links.txt\n",
      "links from page 30 have been added to stock_news_links.txt\n",
      "links from page 29 have been added to stock_news_links.txt\n",
      "links from page 28 have been added to stock_news_links.txt\n",
      "links from page 27 have been added to stock_news_links.txt\n",
      "links from page 26 have been added to stock_news_links.txt\n",
      "links from page 25 have been added to stock_news_links.txt\n",
      "links from page 24 have been added to stock_news_links.txt\n",
      "links from page 23 have been added to stock_news_links.txt\n",
      "links from page 22 have been added to stock_news_links.txt\n",
      "links from page 21 have been added to stock_news_links.txt\n",
      "links from page 20 have been added to stock_news_links.txt\n",
      "links from page 19 have been added to stock_news_links.txt\n",
      "links from page 18 have been added to stock_news_links.txt\n",
      "links from page 17 have been added to stock_news_links.txt\n",
      "links from page 16 have been added to stock_news_links.txt\n",
      "links from page 15 have been added to stock_news_links.txt\n",
      "links from page 14 have been added to stock_news_links.txt\n",
      "links from page 13 have been added to stock_news_links.txt\n",
      "links from page 12 have been added to stock_news_links.txt\n",
      "links from page 11 have been added to stock_news_links.txt\n",
      "links from page 10 have been added to stock_news_links.txt\n",
      "links from page 9 have been added to stock_news_links.txt\n",
      "links from page 8 have been added to stock_news_links.txt\n",
      "links from page 7 have been added to stock_news_links.txt\n",
      "links from page 6 have been added to stock_news_links.txt\n",
      "links from page 5 have been added to stock_news_links.txt\n",
      "links from page 4 have been added to stock_news_links.txt\n",
      "links from page 3 have been added to stock_news_links.txt\n",
      "links from page 2 have been added to stock_news_links.txt\n",
      "links from page 1 have been added to stock_news_links.txt\n",
      "links from page 0 have been added to stock_news_links.txt\n"
     ]
    }
   ],
   "source": [
    "for i in range(141, -1, -1):\n",
    "    getlinks(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
